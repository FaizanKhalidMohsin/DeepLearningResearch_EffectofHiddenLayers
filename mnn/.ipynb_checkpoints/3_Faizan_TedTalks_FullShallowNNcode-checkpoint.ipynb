{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {'model_num':[],\n",
    "        'optimizer':[ ],\n",
    "        'loss_fn':[],\n",
    "        'activation_fn':[],\n",
    "        'output_activation_fn':[],\n",
    "        'epochs':[],\n",
    "        'batch_size':[],\n",
    "        'neurons_in_inputlayer':[],\n",
    "        'num_hiddenlayer':[],\n",
    "        'neurons_in_hiddenlayer':[],\n",
    "        'num_dropout_layers':[],            \n",
    "        'loss':[],\n",
    "        'mse_test':[],\n",
    "        'mae_test':[],\n",
    "        'mape_test':[],\n",
    "        'cosine_similarity_test':[],\n",
    "        'rmse_test':[],\n",
    "        'msle_test':[] \n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame(dict)\n",
    "results_df\n",
    "\n",
    "optimizer_list = [\"nadam\", \"adam\"]\n",
    "loss_fn_list = [\"mse\", \"mae\", \"msle\"]\n",
    "activation_fn_list = [\"relu\", \"selu\"]\n",
    "epochs_list = [50, 100]\n",
    "batch_size_list = [1, 10, 32, 100]\n",
    "num_hiddenlayer_list = [1]\n",
    "neurons_in_hiddenlayer_list = [1, 5, 10]\n",
    "neurons_in_inputlayer_list = [1, 5, 10]\n",
    "num_dropout_layers_list = [0]\n",
    "\n",
    "number_parameters = len(optimizer_list) * len(loss_fn_list) * len(activation_fn_list) * len(epochs_list) * len(batch_size_list) * len(neurons_in_inputlayer_list) * len(neurons_in_hiddenlayer_list) * len(num_dropout_layers_list) \n",
    "print(\"number_parameters :\", number_parameters)\n",
    "\n",
    "print(2*3*2*2*4*3*3)\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "start=datetime.now()\n",
    "\n",
    "\n",
    "number_parameters = len(optimizer_list) * len(loss_fn_list) * len(activation_fn_list) * len(epochs_list) * len(batch_size_list) * len(neurons_in_inputlayer_list) * len(neurons_in_hiddenlayer_list) * len(num_dropout_layers_list) \n",
    "print(\"number_parameters :\", number_parameters)\n",
    "print(number_parameters)\n",
    "\n",
    "i = 0\n",
    "for opt in optimizer_list:\n",
    "    for loss in loss_fn_list:\n",
    "        for activation in activation_fn_list:\n",
    "            for epochs in epochs_list:\n",
    "                for batch in batch_size_list:\n",
    "                    for neurons_in_inputlayer in neurons_in_inputlayer_list:\n",
    "                        for neurons_in_hiddenlayer in neurons_in_hiddenlayer_list:\n",
    "                            \n",
    "                            results = model_results(model_num              = i, \n",
    "                                                    optimizer              = opt ,\n",
    "                                                    loss_fn                = loss, \n",
    "                                                    activation_fn          = activation, \n",
    "                                                    output_activation_fn   = 'relu', \n",
    "                                                    epochs                 = epochs, \n",
    "                                                    batch_size             = batch, \n",
    "                                                    neurons_in_inputlayer  = neurons_in_inputlayer,\n",
    "                                                    num_hiddenlayer        = 1,\n",
    "                                                    neurons_in_hiddenlayer = neurons_in_hiddenlayer,\n",
    "                                                    num_dropout_layers     = 0, \n",
    "                                                    verbose                = 0\n",
    "                                                    )\n",
    "                            \n",
    "                            results_df = results_df.append(results, ignore_index = True)\n",
    "                            print('i:', i)\n",
    "                            print(\"Percent Complete\", 100*i/number_parameters, '%')\n",
    "                            print( ' \\n ')\n",
    "                            print(results)\n",
    "                            print( ' \\n ')\n",
    "                            i+=1\n",
    "                                \n",
    "stop = datetime.now()\n",
    "\n",
    "print('Time: ', stop - start)     \n",
    "\n",
    "# Add information about the data structure to the model results. \n",
    "results_df['corr'] = corr\n",
    "\n",
    "\n",
    "runtime = stop - start\n",
    "print('Time: ', runtime) \n",
    "\n",
    "\n",
    "results_df['total_runtime'] = runtime\n",
    "\n",
    "\n",
    "results_df.to_csv('Experiment5_MultivariableShallowNN_HyperparamSearchResults.csv')\n",
    "\n",
    "\n",
    "results_df.describe()\n",
    "print(results_df.columns)\n",
    "print(len(results_df.columns))\n",
    "\n",
    "results_df.shape\n",
    "results_df.columns\n",
    "\n",
    "\n",
    "results_df_metrics = results_df.loc[:, results_df.columns.str.contains('test')]\n",
    "print(results_df_metrics.shape)\n",
    "print(results_df_metrics.columns)\n",
    "type(results_df_metrics.columns)\n",
    "\n",
    "results_df_metrics.max()\n",
    "maxValueIndex = results_df_metrics.idxmax()\n",
    "maxValueIndex\n",
    "\n",
    "\n",
    "print(results_df_metrics.min())\n",
    "\n",
    "print()\n",
    "minValueIndex = results_df_metrics.idxmin()\n",
    "print(minValueIndex)\n",
    "\n",
    "\n",
    "print(minValueIndex.values)\n",
    "results_df.iloc[minValueIndex.values]\n",
    "\n",
    "\n",
    "# Convert the data from wide format to long format. use pd.melt()\n",
    "\n",
    "results_df_long0 = pd.melt(results_df, id_vars='model_num', value_vars=results_df_metrics.columns)\n",
    "results_df_long0\n",
    "\n",
    "#results_df_long = pd.wide_to_long(results_df, i = \"model_num\", j=\"metric\", stubnames= results_df_metrics.columns)\n",
    "#results_df_long\n",
    "\n",
    "\n",
    "# Summarize the results as boxplots\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1,figsize=(15, 8))\n",
    "sns.boxplot(x='variable', y='value', \n",
    "            data= results_df_long0[results_df_long0.variable!= 'mse_test'], \n",
    "            palette=\"muted\", ax = ax)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "for variable in results_df_metrics:\n",
    "    \n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1)#,figsize=(15, 8))\n",
    "    sns.boxplot(x='variable', y='value', \n",
    "                data= results_df_long0[results_df_long0.variable == variable], \n",
    "                palette=\"muted\", ax = ax)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "# histogram using sns distribution\n",
    "\n",
    "#sns.histplot(results_df.rmse_test)\n",
    "#sns.displot(results_df.rmse_test)\n",
    "\n",
    "#fig, ax = plt.subplots(nrows=3, ncols=2)\n",
    "for metric in results_df_metrics.columns:\n",
    "\n",
    "    #print(metric)\n",
    "    sns.histplot(results_df[metric])\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
