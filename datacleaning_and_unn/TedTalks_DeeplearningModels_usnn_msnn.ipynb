{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Models\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "Importing the data and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Loading data and libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"ted_main.csv\")\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df[['name', 'title', 'description', 'main_speaker', 'speaker_occupation', 'num_speaker', 'duration', 'event', 'film_date', 'published_date', 'comments', 'tags', 'languages', 'ratings', 'related_talks', 'url', 'views']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import datetime\n",
    "df['film_date'] = df['film_date'].apply(lambda x: datetime.datetime.fromtimestamp( int(x)).strftime('%d-%m-%Y'))\n",
    "df['published_date'] = df['published_date'].apply(lambda x: datetime.datetime.fromtimestamp( int(x)).strftime('%d-%m-%Y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "month_order = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "day_order = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['event']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['month'] = df['film_date'].apply(lambda x: month_order[int(x.split('-')[1]) - 1])\n",
    "\n",
    "month_df = pd.DataFrame(df['month'].value_counts()).reset_index()\n",
    "month_df.columns = ['month', 'talks']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in the 'ted' talk data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ted = pd.read_csv('ted_main.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize events into TED and TEDx; exclude those that are non-TED events\n",
    "ted = ted[ted['event'].str[0:3]=='TED'].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ted.loc[:,'event_cat'] = ted['event'].apply(lambda x: 'TEDx' if x[0:4]=='TEDx' else 'TED')\n",
    "print (\"No. of talks remain: \", len(ted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we change the Unix timstamp to human readable date format. Then we extract month and day of week from film date and published date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ted['film_date'] = ted['film_date'].apply(lambda x: datetime.date.fromtimestamp(int(x)))\n",
    "ted['published_date'] = ted['published_date'].apply(lambda x: datetime.date.fromtimestamp(int(x)))\n",
    "ted['film_month'] = ted['film_date'].apply(lambda x: x.month)\n",
    "ted['pub_month'] = ted['published_date'].apply(lambda x: x.month)\n",
    "ted['film_weekday'] = ted['film_date'].apply(lambda x: x.weekday()) # Monday: 0, Sunday: 6\n",
    "ted['pub_weekday'] = ted['published_date'].apply(lambda x: x.weekday())\n",
    "ted[['film_date','published_date']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TED users can give ratings to each talk. There are 14 possible ratings and they will be categorized as positive, negative and neutral:\n",
    "\n",
    "Positive: 'Beautiful', 'Courageous', 'Fascinating', 'Funny', 'Informative', 'Ingenious', 'Inspiring', 'Jaw-dropping', 'Persuasive' Negative: 'Confusing', 'Longwinded', 'Obnoxious', 'Unconvincing' Neutral: 'OK'\n",
    "\n",
    "Here, we define a \"popular\" TED talk by its ratio of positive to negative ratings (which we call it \"popularity ratio\" here). If the popularity ratio is above 5, it is defined as \"Popular\", otherwise it is \"Not Popular\". Transformation is made to avoid \"divided by zero\" error. The following code is adopted from this kernel to convert 'ratings' column (a JSON object) into columns of each rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ted['ratings']=ted['ratings'].str.replace(\"'\",'\"')\n",
    "ted=ted.merge(ted.ratings.apply(lambda x: pd.Series(pd.read_json(x)['count'].values,index=pd.read_json(x)['name'])), \n",
    "            left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Positive = ['Beautiful', 'Courageous', 'Fascinating', 'Funny', 'Informative', 'Ingenious', 'Inspiring', 'Jaw-dropping', 'Persuasive']\n",
    "Negative = ['Confusing', 'Longwinded', 'Obnoxious', 'Unconvincing']\n",
    "ted['positive']=ted.loc[:,Positive].sum(axis=1)+1\n",
    "ted['negative']=ted.loc[:,Negative].sum(axis=1)+1\n",
    "ted['pop_ratio']=ted['positive']/ted['negative']\n",
    "ted.loc[:,'Popular'] = ted['pop_ratio'].apply (lambda x: 1 if x >5 else 0)\n",
    "\n",
    "print (\"No. of Not Popular talks: \", len(ted[ted['Popular']==0]))\n",
    "# print (\"Ratio of Popular talks: {:.4f}\".format(len(ted[ted['Popular']==1])/ float(len(ted))))\n",
    "overall_mean_popular = np.mean(ted.Popular)\n",
    "print (\"Ratio of Popular talks: {:.4f}\".format(overall_mean_popular))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = ['comments', 'duration', 'languages', 'num_speaker', 'views']\n",
    "sns.pairplot(ted, vars=nums, hue='Popular', hue_order = [1,0], diag_kind='kde', height=3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = ['Funny', 'Beautiful', 'Ingenious', 'Courageous', 'Longwinded', 'Confusing', 'Informative', 'Fascinating', 'Unconvincing', \n",
    "           'Persuasive', 'Jaw-dropping', 'OK', 'Obnoxious', 'Inspiring', 'Popular']\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(ted[ratings].corr(), annot=True, cmap='RdBu');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Then we do count vectorizer on 'speaker_occupation'. Before that, some data cleaning is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ted.loc[:,'occ'] = ted.speaker_occupation.copy()\n",
    "ted.occ = ted.occ.fillna('Unknown')\n",
    "ted.occ = ted.occ.str.replace('singer/songwriter', 'singer, songwriter')\n",
    "ted.occ = ted.occ.str.replace('singer-songwriter', 'singer, songwriter')\n",
    "count_vector2 = CountVectorizer(stop_words='english', min_df=20/len(ted))\n",
    "occ_array = count_vector2.fit_transform(ted.occ).toarray()\n",
    "occ_matrix = pd.DataFrame(occ_array, columns = count_vector2.get_feature_names())\n",
    "all_occ = occ_matrix.columns\n",
    "occ_matrix = pd.concat([occ_matrix, ted.Popular], axis=1)\n",
    "by_occ = dict()\n",
    "for col in all_occ:\n",
    "    by_occ[col]=occ_matrix.groupby(col)['Popular'].mean()[1] - overall_mean_popular\n",
    "occ_rank = pd.DataFrame.from_dict(by_occ, orient='index')\n",
    "occ_rank.columns = ['pop_rate_diff']\n",
    "\n",
    "plt.figure(figsize=(16,7))\n",
    "plt.subplot(121)\n",
    "bar_2 = occ_rank.sort_values(by='pop_rate_diff', ascending=False)[:10]\n",
    "sns.barplot(x=bar_2.pop_rate_diff, y=bar_2.index, color='blue')\n",
    "plt.title('10 Most Popular Occupation Keywords', fontsize=14)\n",
    "plt.xlabel('Ratio of Popular Talk (Net of Mean)')\n",
    "plt.yticks(fontsize=12)\n",
    "plt.subplot(122)\n",
    "bar_1 = occ_rank.sort_values(by='pop_rate_diff')[:10]\n",
    "sns.barplot(x=bar_1.pop_rate_diff, y=bar_1.index, color='red')\n",
    "plt.title('10 Most Unpopular Occupation Keywords', fontsize=14)\n",
    "plt.xlabel('Ratio of Popular Talk (Net of Mean)')\n",
    "plt.yticks(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of non-Ted talks that we removed were:\", len(df) - len(ted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structure of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr, _ = pearsonr(df['comments'], df['views']); corr # As can be seen, not much of a correlation between the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we include all the talks will the correlation between comments and views increase or decrease?\n",
    "\n",
    "corr, _ = pearsonr(ted['comments'], ted['views']); corr # it decreases!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word Cloud for popular and nonpopular talks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Popular classification prediction model.\n",
    "\n",
    "We will build a prediction model to prediction which talks are popular, starting with tags, speaker occupations, title and description. As we are having a problem of highly unbalanced class, we only predict a talk to be 'Popular' if the probability of having a 'Popular' label is above 65%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a simple shallow neural network to predict views"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Univariable Shallow network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use comments as input and views as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments = df['comments']; df_views = df['views']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_views"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data in train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_comments, df_views, test_size=0.2, random_state=1)\n",
    "\n",
    "for set in [X_train, X_test, y_train, y_test]:\n",
    "    print( len(set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade keras\n",
    "#pip install --upgrade tensorflow\n",
    "\n",
    "#Import required packages\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import Dropout\n",
    "from keras.metrics import MeanSquaredError, RootMeanSquaredError, MeanAbsolutePercentageError, MeanAbsoluteError, MeanSquaredLogarithmicError, CosineSimilarity\n",
    "from keras import metrics\n",
    "\n",
    "import tensorflow as tf\n",
    "hello = tf.constant('Hello, TensorFlow!')\n",
    "\n",
    "print(hello)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1 (Do not run this cell already have the results saved.)\n",
    "\n",
    "# Specify the modelmodel = Sequential()\n",
    "model_1_neuron = Sequential()\n",
    "model_1_neuron.add(Dense(1, input_dim = 1, activation = \"relu\"))\n",
    "model_1_neuron.compile(loss='mse', optimizer='adam', \n",
    "          #metrics = [\"mse\", \"RMSE\", \"mape\"])\n",
    "            metrics = [ MeanSquaredError(), RootMeanSquaredError(),MeanAbsoluteError(), MeanAbsolutePercentageError(), MeanSquaredLogarithmicError()])\n",
    "\n",
    "\n",
    "# Fit the model, or in other words, train the model. \n",
    "\n",
    "#Train the model and make predictions\n",
    "history = model_1_neuron.fit(X_train, y_train, epochs=100 , batch_size=32, verbose = 2, validation_split=0.2)\n",
    "score = model_1_neuron.evaluate(X_test, y_test, verbose = 2)\n",
    "\n",
    "#Make predictions from the trained model\n",
    "predictions = model_1_neuron.predict(X_test)\n",
    "\n",
    "#print performance and loss\n",
    "print(\"Performance on Test set:\", zip(model_1_neuron.metrics_names, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually get rmse\n",
    "(np.mean((np.array(y_test) - predictions)**2))**.5 # we got 2545996.0559998746 04 April 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# \"Plot Loss\"\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Plot Loss\"\n",
    "#plt.plot(history.history['MeanSquaredError'])\n",
    "#plt.plot(history.history['val_loss'])\n",
    "#plt.title('model Metrics')\n",
    "#plt.ylabel('loss')\n",
    "#plt.xlabel('epoch')\n",
    "#plt.legend(['train', 'validation'], loc='upper right')\n",
    "#plt.show()\n",
    "\n",
    "# plot metrics\n",
    "plt.plot(history.history['mean_squared_error'])\n",
    "#plt.plot(history.history['mean_absolute_error'])\n",
    "#plt.plot(history.history['mean_absolute_percentage_error'])\n",
    "#pyplot.plot(history.history['cosine_proximity'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot metrics\n",
    "plt.plot(history.history['mean_absolute_error'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plot metrics\n",
    "plt.plot(history.history['mean_squared_logarithmic_error'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot metrics\n",
    "plt.plot(history.history['mean_squared_error'])\n",
    "plt.plot(history.history['mean_absolute_error'])\n",
    "plt.plot(history.history['mean_squared_logarithmic_error'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code from book\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2\n",
    "\n",
    "def train_given_optimiser(optimiser):\n",
    "    \n",
    " model = Sequential()\n",
    " model.add(Dense(2, input_dim=1))\n",
    " model.add(Activation(activation='relu'))\n",
    "\n",
    "\n",
    " model.compile(optimizer=optimiser, loss='msle', metrics=['mse', 'mape', RootMeanSquaredError(), 'msle' ])\n",
    "    \n",
    " score = model.evaluate(X_train,y_train, verbose=2)\n",
    "\n",
    " print (\"Optimiser: \", optimiser)\n",
    " print (\"Before Training:\", list(zip(model.metrics_names, score)))\n",
    " model.fit(X_train,y_train, epochs=10, batch_size=32, verbose=0)\n",
    " score = model.evaluate(X_test, y_test, verbose=0)\n",
    " print (\"After Training:\", list(zip(model.metrics_names, score)))\n",
    " print (score)\n",
    " print (model.metrics_names)\n",
    " print (\" \\n \")\n",
    "    \n",
    "# Running function for different optimizers \n",
    "train_given_optimiser(\"sgd\")\n",
    "train_given_optimiser(\"rmsprop\")\n",
    "train_given_optimiser(\"adagrad\")\n",
    "train_given_optimiser(\"adadelta\")\n",
    "train_given_optimiser(\"adam\")\n",
    "train_given_optimiser(\"adamax\")\n",
    "train_given_optimiser(\"nadam\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function that outputs the variables to store in the resutls data frame above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_results(model_num, \n",
    "                  optimizer = 'adam', \n",
    "                  loss_fn = 'mse', \n",
    "                  activation_fn = 'relu', \n",
    "                  output_activation_fn = 'relu', \n",
    "                  \n",
    "                  epochs = 100, \n",
    "                  batch_size =32, \n",
    "                  \n",
    "                  neurons_in_inputlayer = 5, \n",
    "                  num_hiddenlayer = 1,  \n",
    "                  neurons_in_hiddenlayer = 2, \n",
    "                  num_dropout_layers = 0,\n",
    "                  \n",
    "                  verbose = 0):  \n",
    "    \n",
    "    # The Model\n",
    "    \n",
    "    model = Sequential()\n",
    "    # Input Layer\n",
    "    model.add(Dense(neurons_in_inputlayer, input_dim = 1, activation = activation_fn))\n",
    "    # Dropout Layer\n",
    "    #model.add(Dropout(rate = 0.1,seed=100))\n",
    "    # Hidden Layers\n",
    "    model.add(Dense(neurons_in_hiddenlayer,activation = activation_fn))\n",
    "    # Output Layer\n",
    "    model.add(Dense(1,activation = output_activation_fn))\n",
    "\n",
    "    \n",
    "    # Compiling the model\n",
    "    model.compile(loss=loss_fn, optimizer=optimizer,\n",
    "    metrics=['mse', 'mae', 'mape', CosineSimilarity(), RootMeanSquaredError() , MeanSquaredLogarithmicError() ])\n",
    "    # Train the model and make predictions\n",
    "    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose = verbose)\n",
    "    # Evaluate the model\n",
    "    score = model.evaluate(X_test, y_test, verbose = verbose)\n",
    "    \n",
    "    # Make predictions from the trained model\n",
    "    #predictions = model.predict(X_test)\n",
    "    \n",
    "    # Store results\n",
    "    dict = {'model_num':[model_num],\n",
    "        'optimizer':[ optimizer],\n",
    "        'loss_fn':[loss_fn],\n",
    "        'activation_fn':[activation_fn],\n",
    "        'output_activation_fn':[output_activation_fn],\n",
    "        'epochs':[epochs],\n",
    "        'batch_size':[batch_size],\n",
    "        'neurons_in_inputlayer':[neurons_in_inputlayer],\n",
    "        'num_hiddenlayer':[num_hiddenlayer],\n",
    "        'neurons_in_hiddenlayer':[neurons_in_hiddenlayer],\n",
    "        'num_dropout_layers':[num_dropout_layers],            \n",
    "        'loss':[score[0]],\n",
    "        'mse_test':[score[1]],\n",
    "        'mae_test':[score[2]],\n",
    "        'mape_test':[score[3]],\n",
    "        'cosine_similarity_test':[score[4]],\n",
    "        'rmse_test':[score[5]],\n",
    "        'msle_test':[score[6]] \n",
    "       }\n",
    "\n",
    "    results_df = pd.DataFrame(dict)\n",
    "    #print (\"After Training:\", list(zip(model.metrics_names, score)))\n",
    "    return(results_df)\n",
    "\n",
    "model_results(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {'model_num':[],\n",
    "        'optimizer':[ ],\n",
    "        'loss_fn':[],\n",
    "        'activation_fn':[],\n",
    "        'output_activation_fn':[],\n",
    "        'epochs':[],\n",
    "        'batch_size':[],\n",
    "        'neurons_in_inputlayer':[],\n",
    "        'num_hiddenlayer':[],\n",
    "        'neurons_in_hiddenlayer':[],\n",
    "        'num_dropout_layers':[],            \n",
    "        'loss':[],\n",
    "        'mse_test':[],\n",
    "        'mae_test':[],\n",
    "        'mape_test':[],\n",
    "        'cosine_similarity_test':[],\n",
    "        'rmse_test':[],\n",
    "        'msle_test':[] \n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame(dict)\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizer_list = [\"nadam\", \"adam\"]\n",
    "loss_fn_list = [\"mse\", \"mae\", \"msle\"]\n",
    "activation_fn_list = [\"relu\", \"selu\"]\n",
    "epochs_list = [50, 100]\n",
    "batch_size_list = [1, 10, 32, 100]\n",
    "num_hiddenlayer_list = [1]\n",
    "neurons_in_hiddenlayer_list = [1, 5, 10]\n",
    "neurons_in_inputlayer_list = [1, 5, 10]\n",
    "num_dropout_layers_list = [0]\n",
    "\n",
    "number_parameters = len(optimizer_list) * len(loss_fn_list) * len(activation_fn_list) * len(epochs_list) * len(batch_size_list) * len(neurons_in_inputlayer_list) * len(neurons_in_hiddenlayer_list) * len(num_dropout_layers_list) \n",
    "print(\"number_parameters :\", number_parameters)\n",
    "\n",
    "print(2*3*2*2*4*3*3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Grid Search Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "start=datetime.now()\n",
    "\n",
    "\n",
    "number_parameters = len(optimizer_list) * len(loss_fn_list) * len(activation_fn_list) * len(epochs_list) * len(batch_size_list) * len(neurons_in_inputlayer_list) * len(neurons_in_hiddenlayer_list) * len(num_dropout_layers_list) \n",
    "print(\"number_parameters :\", number_parameters)\n",
    "print(number_parameters)\n",
    "\n",
    "i = 0\n",
    "for opt in optimizer_list:\n",
    "    for loss in loss_fn_list:\n",
    "        for activation in activation_fn_list:\n",
    "            for epochs in epochs_list:\n",
    "                for batch in batch_size_list:\n",
    "                    for neurons_in_inputlayer in neurons_in_inputlayer_list:\n",
    "                        for neurons_in_hiddenlayer in neurons_in_hiddenlayer_list:\n",
    "                            \n",
    "                            results = model_results(model_num              = i, \n",
    "                                                    optimizer              = opt ,\n",
    "                                                    loss_fn                = loss, \n",
    "                                                    activation_fn          = activation, \n",
    "                                                    output_activation_fn   = 'relu', \n",
    "                                                    epochs                 = epochs, \n",
    "                                                    batch_size             = batch, \n",
    "                                                    neurons_in_inputlayer  = neurons_in_inputlayer,\n",
    "                                                    num_hiddenlayer        = 1,\n",
    "                                                    neurons_in_hiddenlayer = neurons_in_hiddenlayer,\n",
    "                                                    num_dropout_layers     = 0, \n",
    "                                                    verbose                = 0\n",
    "                                                    )\n",
    "                            \n",
    "                            results_df = results_df.append(results, ignore_index = True)\n",
    "                            print('i:', i)\n",
    "                            print(\"Percent Complete\", 100*i/number_parameters, '%')\n",
    "                            print( ' \\n ')\n",
    "                            print(results)\n",
    "                            print( ' \\n ')\n",
    "                            i+=1\n",
    "                                \n",
    "stop = datetime.now()\n",
    "\n",
    "print('Time: ', stop - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add information about the data structure to the model results. \n",
    "results_df['corr'] = corr\n",
    "\n",
    "runtime = stop - start\n",
    "print('Time: ', runtime)\n",
    "\n",
    "results_df['total_runtime'] = runtime\n",
    "\n",
    "print(results_df)\n",
    "\n",
    "results_df.to_csv('Experiment4_results_views_vs_comments.csv')\n",
    "\n",
    "results_df.describe()\n",
    "print(len(results_df.columns))\n",
    "print(results_df.columns)\n",
    "print(results_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the data from the saved results in the csv file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.read_csv(\"Experimental_results/Experiment4_results_views_vs_comments.csv\")\n",
    "print(results_df.shape)\n",
    "print(results_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each metric find min and max value combinations.\n",
    "# First select the metric columns\n",
    "\n",
    "results_df_metrics = results_df.loc[:, results_df.columns.str.contains('test')]\n",
    "print(results_df_metrics.shape)\n",
    "print(results_df_metrics.columns)\n",
    "type(results_df_metrics.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find max values of the metrics values\n",
    "\n",
    "print(results_df_metrics.max())\n",
    "\n",
    "maxValueIndex = results_df_metrics.idxmax()\n",
    "print(maxValueIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding min values of the metrics\n",
    "\n",
    "print(results_df_metrics.min())\n",
    "\n",
    "print()\n",
    "minValueIndex = results_df_metrics.idxmin()\n",
    "print(minValueIndex)\n",
    "print()\n",
    "print(minValueIndex.values)\n",
    "results_df.iloc[minValueIndex.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert the data from wide format to long format. use pd.melt()\n",
    "\n",
    "results_df_long0 = pd.melt(results_df, id_vars='model_num', value_vars=results_df_metrics.columns)\n",
    "results_df_long0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the hyperparameter search results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize the results as boxplots\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1,figsize=(15, 8))\n",
    "sns.boxplot(x='variable', y='value', \n",
    "            data= results_df_long0[results_df_long0.variable!= 'mse_test'], \n",
    "            palette=\"muted\", ax = ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram using sns distribution\n",
    "\n",
    "#sns.histplot(results_df.rmse_test)\n",
    "#sns.displot(results_df.rmse_test)\n",
    "\n",
    "#fig, ax = plt.subplots(nrows=3, ncols=2)\n",
    "for metric in results_df_metrics.columns:\n",
    "\n",
    "    #print(metric)\n",
    "    sns.histplot(results_df[metric])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This code is amazingly beautiful and I give full credit from where I copied it: Stackoverflow: https://stackoverflow.com/questions/34439/finding-what-methods-a-python-object-hasÂ¶\n",
    "import pandas as pd df = pd.DataFrame([[10, 20, 30], [100, 200, 300]], columns=['foo', 'bar', 'baz']) def get_methods(object, spacing=20): methodList = [] for method_name in dir(object): try: if callable(getattr(object, method_name)): methodList.append(str(method_name)) except: methodList.append(str(method_name)) processFunc = (lambda s: ' '.join(s.split())) or (lambda s: s) for method in methodList: try: print(str(method.ljust(spacing)) + ' ' + processFunc(str(getattr(object, method).doc)[0:90])) except: print(method.ljust(spacing) + ' ' + ' getattr() failed')\n",
    "\n",
    "get_methods(df['foo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize the results\n",
    "\n",
    "#plt.subplots(nrows=1, ncols=1,figsize=(15, 8))\n",
    "sns.boxplot( data=results_df['mse_test', 'mae_test', 'rmse_test', 'msle_test']\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group by summary results: Grouping variables: loss_fn, optimizer, and activation_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will search which combination of hyperparameters performs the best for the different metrics - and which metrics are useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariable Shallow Neural Network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data we will be using will be the 'ted' data since there is more preprossessing done on it. The ted data is missing non-ted talks as they are excluded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning the data: Should the cleaning be done before or after the data splitting. To be 100% sure, it should be done after the splitting. However, the training data is cleaned so should the test data be. This is harder and more work, and because it is harder this is what we will do. To make it easy what is hard, make a function that only needs a data set to be passed in. The biggest issue of first cleaning is that it is possible to have information leak into the rows that will be used as test set from the training set. This 'leaky' problem must be avoided.\n",
    "\n",
    "Obviously, I do know that some steps can be done before splitting the data and no information will be leaked e.g. deleting columns that are not variables. However, I propose just to make a function that does all the cleaning steps and simply applying the functions to both training and test sets. This way everything stays in one place and things are more tracable. Although, yes, it may be over work and better to quickly just get rid of all the columns first before anything is done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Once the data is split into train and test. We could further divide the training data into train and validation sets. So our split of the data will be 60:20:20. What we can then do is while training the model using the 60% of the data also indicate in val_per = .2 so that cross validatio is also performed during the training phase. This three phases allow us to first train all the models, then on the validation set compare all the models and choosing the best performing one, and finally using the test set to find the accuracy of the best model in production. Now one last word. If the data set is very very large people at Dessa implementing deep learning for corporate clients have told me that cross validation can be left out, because the data is so large. My reasoning, if this is indeed the case, is because there is only redundant information learned by performing cross validation. The data is so large the model learns all the information in the data with regular training. Cross validation therefore, I surmise, can also be thought as a data augmentation method, nor a data trend augmentation, but data trend augmentation. Data trend augmentation is creating and replicating patterns in the data that already exist and making them stronger or more detectable.\n",
    "\n",
    "Data Cleaning\n",
    "\n",
    "Questions on data cleaning: Should we normalize the data for neural network models. We do not need to normalize the data for the random forest algorithm. I think we do not need to.\n",
    "\n",
    "I will now perform the data cleaning steps which I first list down here for consision and comprehensive vision:\n",
    "\n",
    "1. Remove columns that are not variables such as the indexing and other book keeping columns.\n",
    "2. Create dummy variables for categorical data.\n",
    "3. Make sure all the data is either numerical or categorical. Dates should be converted to numerical or categorical; should not be left as date type data.\n",
    "4. Any other data cleaning steps that need to be done? Nothing at the moment comes to mind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again look at the data columns and the type of variables they are. \n",
    "\n",
    "\n",
    "print(ted.columns)\n",
    "print(len(ted.columns))\n",
    "\n",
    "# Remove the columns: index, url,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has the day, and month, but not the year the talks were published. It should be created. Here the statistician in me asks is there sufficient benefit so as to create and add the variable, what the statistician is asking is does the cost of increasing the number of variables, which increases the number of degrees of freedom, making the model more flexible worth the variability explained by the model, or the increase in predictive power. The same question phrased by a computer scientist would be by adding this variable are we overfitting?\n",
    "\n",
    "The statistician hence needs reminding that we only care about if the predictive power of the model increases. This is assessed in the tuning phase of the model when the accuracy is measured on the validation set. If including the variable increases the validation set accuracy then the student of computer scientist within me simply states we need not think any further; we are only interested in predictive power and not in explainability in itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will create at the end a cleaned data set called ted_clean.\n",
    "\n",
    "ted1 = ted.drop(['index', 'url', 'main_speaker', 'speaker_occupation', 'occ', 'film_date', \n",
    "                 'event', 'description', 'ratings', 'name', 'title', 'published_date' , 'related_talks', 'tags'], axis =1)\n",
    "print(ted1.columns)\n",
    "print(len(ted1.columns))\n",
    "ted2 = pd.get_dummies(ted1)\n",
    "\n",
    "print(ted2.columns)\n",
    "print(len(ted2.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, of all is it correct that so many are created? Secondly, are the correct ones made into dummy variables (i.e. only categorical data ones)? Lastly, is there a better way or since we are using a deep neural network this is good. Or even what we want?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First the proper non-trivial, but still basic model with proper variables and a deep neural network. Statistically speaking we will now do multivariable analysis, instead of univariable analysis, though still using shallow networks.\n",
    "This only has one categorical variable: event_cat\n",
    "\n",
    "We start with data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting up the training and test data\n",
    "\n",
    "# Seperate the data first into training and testing.\n",
    "X_train, X_test, y_train, y_test = train_test_split( ted2.drop('views', axis = 1), ted['views'], test_size=0.2, random_state=1 )\n",
    "                                                                                     \n",
    "                                                                                     \n",
    "for set in [X_train, X_test, y_train, y_test]:\n",
    "    print( len(set) )\n",
    "    \n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the multivariable shallow network as a function that outputs the results and plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is getting very long. Need to covert this into a script. \n",
    "def model_results(model_num, \n",
    "                  \n",
    "                  #X_train = X_train,\n",
    "                  #y_train = y_train,\n",
    "                  #X_test = X_test, \n",
    "                  #y_test = y_test,\n",
    "                  \n",
    "                  optimizer = 'adam', \n",
    "                  loss_fn = 'mse', \n",
    "                  activation_fn = 'relu', \n",
    "                  output_activation_fn = 'relu', \n",
    "                  \n",
    "                  epochs = 100, \n",
    "                  batch_size =32,\n",
    "                  validation_split = 0.2,\n",
    "                  \n",
    "                  \n",
    "                  neurons_in_inputlayer = 50, \n",
    "                  num_hiddenlayer = 1,  \n",
    "                  neurons_in_hiddenlayer = 40, \n",
    "                  num_dropout_layers = 0,\n",
    "                  \n",
    "                  verbose = 0):  \n",
    "    \n",
    "    # The Model\n",
    "    \n",
    "    input_dimensions = X_train.shape[1]\n",
    "    \n",
    "    model = Sequential()\n",
    "    # Input Layer\n",
    "    model.add(Dense(neurons_in_inputlayer, input_dim = input_dimensions, activation = activation_fn))\n",
    "    # Dropout Layer\n",
    "    #model.add(Dropout(rate = 0.1,seed=100))\n",
    "    # Hidden Layers\n",
    "    model.add(Dense(neurons_in_hiddenlayer,activation = activation_fn))\n",
    "    # Output Layer\n",
    "    model.add(Dense(1,activation = output_activation_fn))\n",
    "\n",
    "    \n",
    "    # Compiling the model\n",
    "    model.compile(loss=loss_fn, optimizer=optimizer,\n",
    "    #metrics=['mse', 'mae', 'mape', CosineSimilarity(), RootMeanSquaredError() , MeanSquaredLogarithmicError() ])\n",
    "    metrics=[ MeanSquaredError(), MeanAbsoluteError(), MeanAbsolutePercentageError() \n",
    "             , CosineSimilarity() , RootMeanSquaredError(), MeanSquaredLogarithmicError()  ]   )\n",
    "\n",
    "    # Train the model and make predictions\n",
    "    model_fit=model.fit(X_train,y_train,epochs=epochs,batch_size=batch_size,verbose=verbose,validation_split=validation_split)\n",
    "    # Evaluate the model\n",
    "    score = model.evaluate(X_test, y_test, verbose = verbose)\n",
    "    \n",
    "    # Make predictions from the trained model\n",
    "    #predictions = model.predict(X_test)\n",
    "    \n",
    "    # Store results\n",
    "    dict = {'model_num':[model_num],\n",
    "        'optimizer':[ optimizer],\n",
    "        'loss_fn':[loss_fn],\n",
    "        'activation_fn':[activation_fn],\n",
    "        'output_activation_fn':[output_activation_fn],\n",
    "        'epochs':[epochs],\n",
    "        'batch_size':[batch_size],\n",
    "        'validation_split':[validation_split],\n",
    "        'input_dimensions':[input_dimensions],\n",
    "        'neurons_in_inputlayer':[neurons_in_inputlayer],\n",
    "        'num_hiddenlayer':[num_hiddenlayer],\n",
    "        'neurons_in_hiddenlayer':[neurons_in_hiddenlayer],\n",
    "        'num_dropout_layers':[num_dropout_layers],            \n",
    "        'loss':[score[0]],\n",
    "        'mse_test':[score[1]],\n",
    "        'mae_test':[score[2]],\n",
    "        'mape_test':[score[3]],\n",
    "        'cosine_similarity_test':[score[4]],\n",
    "        'rmse_test':[score[5]],\n",
    "        'msle_test':[score[6]] \n",
    "       }\n",
    "    \n",
    "    \n",
    "    # \"Plot Loss\"\n",
    "    plt.plot(model_fit.history['loss'])\n",
    "    plt.plot(model_fit.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper right')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    # Plot metrics\n",
    "    for metric in ['mean_squared_error', 'root_mean_squared_error' ,'mean_absolute_error', 'mean_absolute_percentage_error','cosine_similarity', 'mean_squared_logarithmic_error']:\n",
    "        plt.plot(model_fit.history[metric])\n",
    "        plt.title('Model Metric: '+ metric)\n",
    "        plt.ylabel(metric)\n",
    "        plt.xlabel('epoch')\n",
    "        #plt.plot(model_fit.history['mean_squared_error'])\n",
    "        #plt.plot(model_fit.history['mean_absolute_error'])\n",
    "        #plt.plot(model_fit.history['mean_absolute_percentage_error'])\n",
    "        #pyplot.plot(model_fit.history['cosine_proximity'])\n",
    "        plt.show()\n",
    "\n",
    "    results_df = pd.DataFrame(dict)\n",
    "    #print (\"After Training:\", list(zip(model.metrics_names, score)))\n",
    "    return(results_df)\n",
    "\n",
    "model_0 = model_results(0)\n",
    "model_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(804724.75/2035016.625)\n",
    "print(100*(2035016.625 - 804724.75) / 2035016.625)\n",
    "print((804724.75/2035016.625)**-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.barplot(x=[\"univariable neural network\", \"multivariable neural network\"], y=[2035016.625,804724.75])\n",
    "ax.set_ylabel(\"RMSE\")\n",
    "ax.set_title(\"Univariable vs. Multivariable Shallow NN\")\n",
    "#ax1.set_ylabel('volts')\n",
    "plt.savefig('test_rmse_usnn_vs_msnn.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "We can see there is a clear improvement using the multivariable model over the univariable model. A 60.46% improvement over the univariable model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (Report3_tedtalk_project)",
   "language": "python",
   "name": "pycharm-15d11b97"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
